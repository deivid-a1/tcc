# Seleção de Modelo LLM para Assistente Acadêmico

## Objetivo
Selecionar modelo LLM para assistente acadêmico com execução local, function calling e chain-of-thought reasoning.

## Hardware Disponível
- **GPU:** NVIDIA A2 (15GB VRAM)
- **Limitação:** Modelos até ~14B parâmetros com quantização

## Requisitos Essenciais
1. **Function Calling** - Integração com ferramentas acadêmicas
2. **Chain-of-Thought** - Raciocínio explícito e estruturado  
3. **Execução Local** - Conformidade LGPD
4. **Estabilidade** - Adequado para pesquisa acadêmica

## Modelos Avaliados

### Qwen2.5-14B-Instruct
- **Lançamento:** 19/09/2024 (5 meses de maturidade)
- **VRAM:** ~14GB (quantização 4-bit)
- **Function Calling:** Superior - Framework Qwen-Agent nativo
- **Performance:** Outperformed GPT-4 e GPT-4o em aplicações específicas de agentes
- **Licença:** Apache 2.0

### Hermes-3-Llama-3.1-8B  
- **Lançamento:** 15/08/2024 (6 meses de maturidade)
- **VRAM:** ~8GB (quantização 4-bit)
- **Function Calling:** Robusto - Framework próprio disponível
- **Performance:** 90% accuracy em function calling, 84% em structured outputs
- **Licença:** Llama 3.1 Community

### Modelos Descartados
- **Qwen3-14B:** Muito recente (abr/2025) - risco para TCC
- **DeepSeek-V3/R1:** Function calling não suportado
- **Modelos >20B:** Incompatível com 15GB VRAM

## Comparação Objetiva

| Critério | Qwen2.5-14B | Hermes-3-8B |
|----------|-------------|-------------|
| **Function Calling** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐⭐ |
| **VRAM (4-bit)** | 14GB (93%) | 8GB (53%) |
| **Maturidade** | 5 meses | 6 meses |
| **Framework** | Qwen-Agent | Custom |
| **Performance** | Superior em agentes | Excelente geral |

## Evidências de Performance

### Qwen2.5-14B
- Developers started calling it the best LLM for coding
- Specifically tuned for instruction-following tasks including SQL tools
- Agent framework com Function Calling, MCP, Code Interpreter

### Hermes-3-8B
- Advanced agentic capabilities, better reasoning, multi-turn conversation
- More powerful and reliable function calling and structured output capabilities

## Decisão

**Modelo Principal:** Qwen2.5-14B-Instruct
**Alternativa:** Hermes-3-Llama-3.1-8B

### Justificativa
1. **Performance Superior:** Comprovadamente melhor em tarefas agentic
2. **Framework Maduro:** Qwen-Agent com 5 meses de estabilidade
3. **Adequação ao Hardware:** Utiliza eficientemente os 15GB disponíveis
4. **Reprodutibilidade:** Essencial para validação científica

### Implementação
```python
# Stack recomendado
Modelo: Qwen2.5-14B-Instruct (GPTQ-4bit)
Framework: Qwen-Agent
Inference: vLLM
Context: 32K tokens
```

### Plano de Contingência
- **Fallback:** Hermes-3-8B se VRAM insuficiente
- **Backup:** Qwen2.5-7B com quantização agressiva

## Cronograma de Validação
1. **Semana 1-2:** Setup e carregamento do modelo
2. **Semana 3-4:** Implementação function calling  
3. **Semana 5-6:** Integração ferramentas acadêmicas
4. **Semana 7-8:** Testes e documentação

## Métricas de Sucesso
- Function Calling Accuracy: >85%
- Response Latency: <3s
- Tool Integration: 100% das ferramentas planejadas