# Model Context Protocol (MCP): Levantamento Teórico

## Definição

O Model Context Protocol (MCP) é um padrão aberto desenvolvido pela Anthropic em novembro de 2024 para padronizar a comunicação entre modelos de linguagem e sistemas externos.

## Arquitetura

### Estrutura Cliente-Servidor
```
[Host Application] → [MCP Client] ↔ [MCP Server] → [External System]
```

### Componentes
- **MCP Host**: Aplicação que contém o LLM (ex: Claude Desktop)
- **MCP Client**: Interface dentro do host que gerencia conexões
- **MCP Server**: Programa que expõe recursos de sistemas externos

## Protocolo de Comunicação

### Base Técnica
- **Protocolo**: JSON-RPC 2.0
- **Transporte**: stdio (local) ou HTTP+SSE (remoto)
- **Sessão**: Stateful e bidirecional

### Primitivas do MCP
1. **Resources**: Dados somente leitura (similar a endpoints GET)
2. **Tools**: Funções executáveis (similar a endpoints POST)
3. **Prompts**: Templates de instruções pré-definidos

## Funcionamento

### Fluxo de Comunicação
1. **Inicialização**: Cliente e servidor trocam capacidades
2. **Descoberta**: Cliente lista tools/resources disponíveis
3. **Execução**: Cliente solicita execução de tool/resource
4. **Resposta**: Servidor retorna resultado estruturado

### Exemplo de Interação
```json
// Cliente solicita lista de tools
{"jsonrpc": "2.0", "method": "tools/list", "id": 1}

// Servidor responde com tools disponíveis
{
  "jsonrpc": "2.0", 
  "id": 1,
  "result": {
    "tools": [{
      "name": "get_weather",
      "description": "Get current weather",
      "inputSchema": {...}
    }]
  }
}
```

## Comparação com Function Calling

| Aspecto | Function Calling | MCP |
|---------|------------------|-----|
| **Escopo** | Chamadas de função | Protocolo completo |
| **Padrão** | Específico por provedor | Universal aberto |
| **Sessão** | Stateless | Stateful |
| **Tipos** | Apenas functions | Resources + Tools + Prompts |
| **Descoberta** | Manual | Automática |
| **Transporte** | HTTP | stdio + HTTP |

## Adoção Atual

### Suporte Oficial
- **Anthropic**: Claude Desktop (nativo)
- **OpenAI**: ChatGPT Desktop, Agents SDK (março 2025)
- **Microsoft**: Copilot Studio, Azure (maio 2025)
- **Google**: Gemini (confirmado para futuro)

### Ecossistema
- **IDEs**: Cursor, Windsurf, Zed, Replit
- **SDKs**: Python, TypeScript (oficiais), C#, Java
- **Deployment**: Cloudflare, Azure

## Vantagens

### Padronização
- Interface única para diferentes sistemas
- Redução do problema N×M para N+M
- Interoperabilidade entre provedores de LLM

### Flexibilidade
- Suporte a múltiplos tipos de dados (Resources/Tools/Prompts)
- Comunicação local (stdio) e remota (HTTP)
- Sessões stateful para contexto persistente

### Segurança
- Isolamento por processo
- Controle granular de acesso
- Execução local possível

## Limitações

### Complexidade
- Overhead do protocolo JSON-RPC
- Necessidade de implementar cliente e servidor
- Curva de aprendizado para desenvolvedores

### Maturidade
- Padrão recente (novembro 2024)
- Ecossistema ainda em desenvolvimento
- Documentação e ferramentas em evolução

## Casos de Uso

### Desenvolvimento
- Integração com IDEs e ferramentas de código
- Acesso a repositórios (Git, GitHub)
- Automação de workflows

### Produtividade
- Conexão com Google Drive, Slack
- Integração com bases de dados
- Automação de tarefas empresariais

### Domínios Específicos
- Sistemas de saúde (inspiração no HL7 FHIR)
- Sistemas educacionais
- Ferramentas de análise de dados